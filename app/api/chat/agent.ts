import {
  StateGraph,
  MessagesAnnotation,
  START,
  END,
} from "@langchain/langgraph";
import { ToolNode } from "@langchain/langgraph/prebuilt";
import { ChatOpenAI } from "@langchain/openai";
import { tool } from "@langchain/core/tools";
import {
  AIMessage,
  SystemMessage,
  HumanMessage,
  BaseMessage,
} from "@langchain/core/messages";
import { z } from "zod";

// ============================================================
// Tool Definitions
// ============================================================

const confirmAction = tool(
  async ({ action, description }) => {
    return JSON.stringify({
      type: "confirmation_required",
      action,
      description,
      status: "pending",
    });
  },
  {
    name: "confirm_action",
    description:
      "When you need user confirmation before performing a potentially dangerous or important action, use this tool. It will display a confirmation dialog to the user.",
    schema: z.object({
      action: z.string().describe("The action name that needs confirmation"),
      description: z
        .string()
        .describe("A detailed description of what will happen if confirmed"),
    }),
  }
);

const searchKnowledge = tool(
  async ({ query }) => {
    return JSON.stringify({
      type: "search_result",
      query,
      results: [
        `Found relevant information about: ${query}`,
        "This is a simulated search result for the MVP demo.",
      ],
    });
  },
  {
    name: "search_knowledge",
    description:
      "Search the knowledge base for relevant information. Use this when the user asks about specific topics.",
    schema: z.object({
      query: z.string().describe("The search query"),
    }),
  }
);

const calculateData = tool(
  async ({ expression }) => {
    try {
      const result = Function(`"use strict"; return (${expression})`)();
      return JSON.stringify({ type: "calculation", expression, result });
    } catch {
      return JSON.stringify({
        type: "calculation_error",
        expression,
        error: "Invalid expression",
      });
    }
  },
  {
    name: "calculate",
    description: "Perform a mathematical calculation.",
    schema: z.object({
      expression: z
        .string()
        .describe("The mathematical expression to evaluate"),
    }),
  }
);

// execute_python: bound to the model so it can call it,
// but never executed server-side â€” handled via HITL on the client.
const executePython = tool(
  async () => {
    return JSON.stringify({ type: "hitl_required" });
  },
  {
    name: "execute_python",
    description:
      "Execute Python code in a fresh Jupyter notebook sandbox and return the result. IMPORTANT: Each invocation creates a NEW isolated sandbox â€” variables, imports, and files from previous executions are NOT available. Every code block MUST be fully self-contained with all imports, file reads (e.g. pd.read_csv('/home/user/xxx.csv')), and variable definitions. If a task has multiple steps, combine them into a single code block. The sandbox has common data science packages pre-installed (pandas, numpy, matplotlib, seaborn, scikit-learn, etc.).",
    schema: z.object({
      code: z
        .string()
        .describe(
          "The complete, self-contained Python code to execute. MUST include all necessary imports, data loading, and variable definitions â€” do NOT reference variables from previous executions."
        ),
    }),
  }
);

/** Safe tools â€” auto-executed by the ToolNode inside the graph */
const safeTools = [confirmAction, searchKnowledge, calculateData];

/** All tools â€” bound to the model so the LLM can call any of them */
const allTools = [...safeTools, executePython];

// ============================================================
// System Prompt
// ============================================================

const SYSTEM_PROMPT = `ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½æ•°æ®åˆ†æåŠ©æ‰‹ (Next Analyst)ã€‚ä½ å¯ä»¥å¸®åŠ©ç”¨æˆ·è¿›è¡Œæ•°æ®åˆ†æã€å›ç­”é—®é¢˜ã€æ‰§è¡Œè®¡ç®—ã€ç¼–å†™å’Œè¿è¡ŒPythonä»£ç ã€‚
      
ä½ æœ‰ä»¥ä¸‹å·¥å…·å¯ä»¥ä½¿ç”¨:
- execute_python: åœ¨Jupyteræ²™ç›’ä¸­æ‰§è¡ŒPythonä»£ç ï¼Œé€‚ç”¨äºæ•°æ®åˆ†æã€æ•°æ®å¤„ç†ã€ç”Ÿæˆå›¾è¡¨ã€å¤æ‚è®¡ç®—ç­‰åœºæ™¯ã€‚æ²™ç›’å·²é¢„è£… pandas, numpy, matplotlib, seaborn, scikit-learn ç­‰å¸¸ç”¨åº“ã€‚
- confirm_action: å½“éœ€è¦ç”¨æˆ·ç¡®è®¤é‡è¦æ“ä½œæ—¶ä½¿ç”¨
- search_knowledge: æœç´¢çŸ¥è¯†åº“è·å–ä¿¡æ¯
- calculate: æ‰§è¡Œç®€å•æ•°å­¦è®¡ç®—

é‡è¦è§„åˆ™:
1. å½“ç”¨æˆ·éœ€è¦æ•°æ®åˆ†æã€å¤„ç†æ•°æ®ã€ç”Ÿæˆå›¾è¡¨ã€æˆ–ä»»ä½•éœ€è¦ç¼–ç¨‹è§£å†³çš„é—®é¢˜æ—¶ï¼Œä¼˜å…ˆä½¿ç”¨ execute_python å·¥å…·ã€‚
2. è¯·ç”¨ä¸­æ–‡å›ç­”é—®é¢˜ã€‚
3. å¦‚æœç”¨æˆ·è¦æ±‚æ‰§è¡Œé‡è¦æ“ä½œï¼ˆå¦‚åˆ é™¤æ•°æ®ã€ä¿®æ”¹é…ç½®ç­‰ï¼‰ï¼Œè¯·å…ˆä½¿ç”¨ confirm_action å·¥å…·è·å–ç”¨æˆ·ç¡®è®¤ã€‚
4. æ‰§è¡Œä»£ç åï¼Œè¯·è§£é‡Šä»£ç çš„æ‰§è¡Œç»“æœã€‚
5. å½“ç”¨æˆ·ä¸Šä¼ æ–‡ä»¶æ—¶ï¼Œæ–‡ä»¶ä¼šè‡ªåŠ¨ä¸Šä¼ åˆ°æ²™ç®±ç¯å¢ƒçš„ /home/user/ ç›®å½•ã€‚åœ¨Pythonä»£ç ä¸­é€šè¿‡è¯¥è·¯å¾„è¯»å–æ–‡ä»¶ï¼Œä¾‹å¦‚: pd.read_csv('/home/user/data.csv')ã€‚
6. ä½ ä¼šæ”¶åˆ°ç³»ç»Ÿé€šè¿‡æ²™ç›’è‡ªåŠ¨è§£æçš„æ•°æ®æ–‡ä»¶ç»“æ„ä¿¡æ¯ï¼ŒåŒ…æ‹¬ï¼šåˆ—åã€æ•°æ®ç±»å‹ã€å‰5è¡Œæ•°æ®ã€ç»Ÿè®¡æ‘˜è¦å’Œç©ºå€¼æƒ…å†µã€‚è¯·å……åˆ†åˆ©ç”¨è¿™äº›ç»“æ„åŒ–ä¿¡æ¯æ¥åˆ¶å®šå‡†ç¡®çš„æ•°æ®åˆ†ææ–¹æ¡ˆï¼Œä¸è¦å‡è®¾æ–‡ä»¶æœ‰ä½ æœªçœ‹åˆ°çš„åˆ—æˆ–æ•°æ®ç»“æ„ã€‚
7. å¦‚æœæ”¶åˆ°æ–‡ä»¶çš„ç»“æ„åŒ–é¢„è§ˆä¿¡æ¯ï¼Œè¯·å…ˆå‘ç”¨æˆ·ç®€è¦æè¿°æ•°æ®æ¦‚å†µï¼ˆè¡Œåˆ—æ•°ã€ä¸»è¦å­—æ®µã€æ•°æ®ç±»å‹ç­‰ï¼‰ï¼Œç„¶åæ ¹æ®ç”¨æˆ·éœ€æ±‚åˆ¶å®šåˆ†ææ–¹æ¡ˆï¼Œæœ€åç”Ÿæˆæ‰§è¡Œä»£ç ã€‚
8. ã€ä»£ç å—ç‹¬ç«‹å®Œæ•´åŸåˆ™ã€‘æ¯æ¬¡è°ƒç”¨ execute_python æ—¶ï¼Œæ²™ç›’ç¯å¢ƒéƒ½æ˜¯å…¨æ–°çš„ï¼Œå‰ä¸€æ¬¡æ‰§è¡Œçš„å˜é‡ã€å¯¼å…¥çš„åº“ã€åŠ è½½çš„æ•°æ®åœ¨ä¸‹ä¸€æ¬¡æ‰§è¡Œä¸­ä¸å¯ç”¨ã€‚å› æ­¤ï¼Œæ¯ä¸ªä»£ç å—å¿…é¡»æ˜¯å®Œå…¨ç‹¬ç«‹çš„ã€å¯ç›´æ¥è¿è¡Œçš„å®Œæ•´ä»£ç ï¼ŒåŒ…æ‹¬:
   - æ‰€æœ‰å¿…è¦çš„ import è¯­å¥
   - é‡æ–°è¯»å–/åŠ è½½æ•°æ®æ–‡ä»¶ï¼ˆå¦‚ pd.read_csv('/home/user/xxx.csv')ï¼‰
   - é‡æ–°å®šä¹‰æ‰€æœ‰éœ€è¦ç”¨åˆ°çš„å˜é‡å’Œå‡½æ•°
   - ä¸å¾—å¼•ç”¨æˆ–ä¾èµ–å‰ä¸€ä¸ªä»£ç å—ä¸­å®šä¹‰çš„ä»»ä½•å˜é‡
   ç»å¯¹ä¸è¦å‡è®¾ä¹‹å‰çš„ä»£ç å—å·²ç»æ‰§è¡Œè¿‡æˆ–å…¶å˜é‡ä»ç„¶å­˜åœ¨ã€‚å¦‚æœä¸€ä¸ªåˆ†æä»»åŠ¡éœ€è¦å¤šä¸ªæ­¥éª¤ï¼Œå°½é‡å°†å®ƒä»¬åˆå¹¶åˆ°ä¸€ä¸ªä»£ç å—ä¸­æ‰§è¡Œã€‚
9. ã€ç”Ÿæˆæ–‡ä»¶è‡ªåŠ¨ä¿ç•™ã€‘ä»£ç æ‰§è¡Œä¸­ç”Ÿæˆçš„æ–°æ–‡ä»¶ï¼ˆå¦‚æ¸…æ´—åçš„æ•°æ®é›†ã€å¤„ç†ç»“æœç­‰ï¼‰ä¼šè‡ªåŠ¨ä¿ç•™åœ¨ä¼šè¯ä¸­ã€‚åç»­ä»£ç æ‰§è¡Œæ—¶ï¼Œè¿™äº›æ–‡ä»¶ä¼šè¢«è‡ªåŠ¨ä¸Šä¼ åˆ°æ²™ç›’çš„ /home/user/ ç›®å½•ï¼Œå¯ç›´æ¥é€šè¿‡è·¯å¾„è®¿é—®ã€‚å½“ä¼šè¯æ–‡ä»¶åˆ—è¡¨ä¸­åŒæ—¶å­˜åœ¨åŸå§‹æ–‡ä»¶å’Œå¤„ç†åçš„æ–‡ä»¶æ—¶ï¼Œè¯·æ ¹æ®ç”¨æˆ·éœ€æ±‚é€‰æ‹©åˆé€‚çš„æ–‡ä»¶è¿›è¡Œæ“ä½œï¼ˆé€šå¸¸åº”ä½¿ç”¨æœ€æ–°å¤„ç†è¿‡çš„æ–‡ä»¶ï¼‰ã€‚
10. ã€matplotlib å›¾è¡¨è§„èŒƒã€‘ç”Ÿæˆå›¾è¡¨æ—¶åŠ¡å¿…éµå®ˆä»¥ä¸‹è§„èŒƒä»¥é¿å…é‡å¤æ˜¾ç¤ºï¼š
   - è°ƒç”¨ plt.savefig() ä¿å­˜å›¾ç‰‡åï¼Œå¿…é¡»ç´§æ¥ç€è°ƒç”¨ plt.close('all') å…³é—­å›¾å½¢
   - ä¸è¦åœ¨ä¿å­˜åå†è°ƒç”¨ plt.show()
   - ä¸è¦ç”¨ PIL/Image æ‰“å¼€åˆšä¿å­˜çš„å›¾ç‰‡æ–‡ä»¶æ¥æ˜¾ç¤º
   - æ­£ç¡®æ¨¡å¼: plt.savefig('output.png', dpi=150, bbox_inches='tight'); plt.close('all'); print('å›¾è¡¨å·²ä¿å­˜ä¸º output.png')
   - å¦‚æœä¸éœ€è¦ä¿å­˜ä¸ºæ–‡ä»¶åªæ˜¯å±•ç¤ºï¼Œå¯ä»¥ä½¿ç”¨ plt.show() ä½†ä¸è¦åŒæ—¶ savefig`;

// ============================================================
// Helpers â€” File Context & Message Building
// ============================================================

export interface FileInfo {
  name: string;
  size: number;
  preview: string;
  isGenerated?: boolean;
  richPreview?: {
    fileName: string;
    shape: [number, number];
    columns: string[];
    dtypes: Record<string, string>;
    head: string;
    describe: string;
    null_counts: Record<string, number>;
  };
}

function formatFileContext(f: FileInfo): string {
  const sourceTag = f.isGenerated ? " [ä»£ç æ‰§è¡Œç”Ÿæˆ]" : " [ç”¨æˆ·ä¸Šä¼ ]";
  if (f.richPreview) {
    const rp = f.richPreview;
    const nullInfo = Object.entries(rp.null_counts)
      .filter(([, v]) => v > 0)
      .map(([k, v]) => `  ${k}: ${v}ä¸ªç©ºå€¼`)
      .join("\n");
    return `ğŸ“ æ–‡ä»¶: ${f.name}${sourceTag} (${f.size} bytes)
ğŸ“Š æ•°æ®æ¦‚å†µ: ${rp.shape[0]}è¡Œ Ã— ${rp.shape[1]}åˆ—
ğŸ“‹ åˆ—å: ${rp.columns.join(", ")}
ğŸ“‹ åˆ—ç±»å‹:\n${Object.entries(rp.dtypes).map(([k, v]) => `  ${k}: ${v}`).join("\n")}
ğŸ“‹ å‰5è¡Œæ•°æ®:\n\`\`\`\n${rp.head}\n\`\`\`
ğŸ“‹ ç»Ÿè®¡æ‘˜è¦:\n\`\`\`\n${rp.describe}\n\`\`\`${nullInfo ? `\nâš ï¸ ç©ºå€¼æƒ…å†µ:\n${nullInfo}` : ""}
åœ¨Pythonä»£ç ä¸­ä½¿ç”¨è·¯å¾„: /home/user/${f.name}`;
  }
  return `ğŸ“ æ–‡ä»¶: ${f.name}${sourceTag} (${f.size} bytes)\næ–‡ä»¶å†…å®¹é¢„è§ˆ(å‰å‡ è¡Œ):\n\`\`\`\n${f.preview}\n\`\`\`\nåœ¨Pythonä»£ç ä¸­ä½¿ç”¨è·¯å¾„: /home/user/${f.name}`;
}

interface ToolResultPayload {
  code?: string;
  stdout?: string;
  stderr?: string;
  error?: string;
  results?: Array<{ text?: string; png?: string; html?: string }>;
  generatedFiles?: Array<{ name: string; size: number }>;
}

/**
 * Build the LangChain message array from the HTTP request payload.
 */
export function buildLangChainMessages(
  messages: Array<{ role: string; content: string }>,
  files: FileInfo[] | undefined,
  toolResult: ToolResultPayload | undefined,
  sessionFiles: FileInfo[] | undefined
): BaseMessage[] {
  // --- Session-level file context (injected into the system prompt) ---
  let sessionFileContext = "";
  const effectiveSessionFiles: FileInfo[] =
    sessionFiles && Array.isArray(sessionFiles) && sessionFiles.length > 0
      ? sessionFiles
      : files && Array.isArray(files) && files.length > 0
        ? files
        : [];
  if (effectiveSessionFiles.length > 0) {
    sessionFileContext =
      "\n\nã€å½“å‰ä¼šè¯ä¸­å¯ç”¨çš„æ•°æ®æ–‡ä»¶ã€‘\n" +
      effectiveSessionFiles.map((f) => formatFileContext(f)).join("\n\n");
  }

  // --- Inject new file context into the last user message ---
  let processedMessages = messages;
  if (files && Array.isArray(files) && files.length > 0) {
    const newFileContext = files
      .map((f) => `\n\n` + formatFileContext(f))
      .join("");
    processedMessages = messages.map((msg, index) => {
      if (index === messages.length - 1 && msg.role === "user") {
        return { ...msg, content: msg.content + newFileContext };
      }
      return msg;
    });
  }

  // --- Convert to LangChain message objects ---
  const langchainMessages: BaseMessage[] = [
    new SystemMessage(SYSTEM_PROMPT + sessionFileContext),
    ...processedMessages.map((msg) => {
      if (msg.role === "user") return new HumanMessage(msg.content);
      if (msg.role === "assistant") return new AIMessage(msg.content);
      return new HumanMessage(msg.content);
    }),
  ];

  // --- If continuing after HITL execution, append the result ---
  if (toolResult) {
    const resultParts: string[] = [];
    if (toolResult.code)
      resultParts.push(
        `æ‰§è¡Œçš„ä»£ç :\n\`\`\`python\n${toolResult.code}\n\`\`\``
      );
    if (toolResult.stdout)
      resultParts.push(`æ ‡å‡†è¾“å‡º:\n${toolResult.stdout}`);
    if (toolResult.stderr)
      resultParts.push(`æ ‡å‡†é”™è¯¯:\n${toolResult.stderr}`);
    if (toolResult.error)
      resultParts.push(`é”™è¯¯: ${toolResult.error}`);
    if (toolResult.results && toolResult.results.length > 0) {
      const descriptions = toolResult.results
        .map((r) => {
          if (r.png) return "[ç”Ÿæˆäº†å›¾è¡¨]";
          if (r.text) return r.text;
          if (r.html) return "[ç”Ÿæˆäº†HTMLå†…å®¹]";
          return "";
        })
        .filter(Boolean);
      if (descriptions.length > 0)
        resultParts.push(`æ‰§è¡Œç»“æœ:\n${descriptions.join("\n")}`);
    }
    if (
      toolResult.generatedFiles &&
      Array.isArray(toolResult.generatedFiles) &&
      toolResult.generatedFiles.length > 0
    ) {
      const fileDescs = toolResult.generatedFiles
        .map((f) => `- /home/user/${f.name} (${f.size} bytes)`)
        .join("\n");
      resultParts.push(
        `ç”Ÿæˆçš„æ–°æ–‡ä»¶:\n${fileDescs}\nè¿™äº›æ–‡ä»¶å·²ä¿å­˜åœ¨ä¼šè¯ä¸­ï¼Œåç»­ä»£ç æ‰§è¡Œæ—¶å¯é€šè¿‡ä¸Šè¿°è·¯å¾„è®¿é—®ã€‚`
      );
    }
    langchainMessages.push(
      new HumanMessage(
        `[ç³»ç»Ÿæ¶ˆæ¯] ä¹‹å‰è¯·æ±‚çš„Pythonä»£ç å·²æ‰§è¡Œå®Œæ¯•ï¼Œç»“æœå¦‚ä¸‹:\n\n${resultParts.join("\n\n")}\n\nè¯·æ ¹æ®æ‰§è¡Œç»“æœä¸ºç”¨æˆ·æä¾›åˆ†æå’Œè§£é‡Šã€‚`
      )
    );
  }

  return langchainMessages;
}

// ============================================================
// LangGraph â€” Graph Definition
// ============================================================

/**
 * Conditional router executed after the "agent" node.
 *
 * - If the model produced NO tool calls â†’ END (text-only response).
 * - If the model called `execute_python` â†’ END (HITL â€” the client
 *   will show a confirmation card, execute the code, and send a
 *   follow-up request with the result).
 * - Otherwise â†’ route to the "tools" node for auto-execution.
 */
function routeAfterAgent(
  state: typeof MessagesAnnotation.State
): typeof END | "tools" {
  const lastMsg = state.messages[state.messages.length - 1];

  if (
    "tool_calls" in lastMsg &&
    Array.isArray((lastMsg as AIMessage).tool_calls) &&
    (lastMsg as AIMessage).tool_calls!.length > 0
  ) {
    const toolCalls = (lastMsg as AIMessage).tool_calls!;

    // execute_python requires human-in-the-loop â†’ stop the graph
    if (toolCalls.some((tc) => tc.name === "execute_python")) {
      return END;
    }

    // All tool calls are safe â€” let the ToolNode handle them
    return "tools";
  }

  // No tool calls â€” done
  return END;
}

/**
 * Create and compile the LangGraph agent graph.
 *
 * ```
 * START â†’ agent â”€â”¬â”€ (no tools)          â†’ END
 *                 â”œâ”€ (execute_python)    â†’ END  (HITL)
 *                 â””â”€ (safe tools)        â†’ tools â†’ agent
 * ```
 */
export function createGraph() {
  const model = new ChatOpenAI({
    apiKey: process.env.OPENAI_API_KEY,
    configuration: {
      baseURL: process.env.OPENAI_BASE_URL,
    },
    model: process.env.LLM_MODEL || "qwen3-coder",
    temperature: 0.7,
    streaming: true,
  }).bindTools(allTools);

  // Agent node â€” invoke the LLM
  const callModel = async (state: typeof MessagesAnnotation.State) => {
    const response = await model.invoke(state.messages);
    return { messages: [response] };
  };

  // Tool node â€” auto-execute safe tools only
  const toolNode = new ToolNode(safeTools);

  const graph = new StateGraph(MessagesAnnotation)
    .addNode("agent", callModel)
    .addNode("tools", toolNode)
    .addEdge(START, "agent")
    .addConditionalEdges("agent", routeAfterAgent)
    .addEdge("tools", "agent")
    .compile();

  return graph;
}
